{
    "contents" : "# GROUP 7 - AUTO INSURANCE - ANALYSIS & PREDICTION\n\nRegression and Variable Selection\n=================================================\n  \n  The objective of this project is to analyze historical\nauto insurance loss data and predict insurance company's \nfuture losses based on customer demographics.\n\n\nAuto Insurance Data\n===================\n### LOAD LIBRARY\nlibrary(\"lmtest\")\nlibrary(\"sandwich\")\n###READ THE DATASET\nrm(list=ls())\nInsuranceData=read.csv(file=\"Insurance Data Updated.csv\")\nattach(InsuranceData)\n\nThe original data are 15,290 observations on 8 variables,\nlosses being the response variable $y$.\n\nVariable Description\n----------------------\nAge | Age of policy holder\nYears of Driving Experience | Years driven \nNumber of Vehicles  | Number of Cars insured under policy \nGender | M/F\nMarried | Married/Single\nVehicle Age | Age of vehicle insured under policy\nFuel Type | Petro/Diesel\nLosses | Loss claimed under policy\n\n\n### sampling (Split Dataset Randomly)\nNext we sample 90% of the original data and use it \nas the training set. The remaining 10% is used \nas test set. The regression model will be built \non the training set and future performance \nof your model will be evaluated with the test set.\n\n```{r}\nset.seed(1000)\nsubset <- sample(nrow(InsuranceData),nrow(InsuranceData)*0.90)\nInsurance_train = InsuranceData[subset,]\nInsurance_test = InsuranceData[-subset,]\n```\n\n\nData Analysis and Visualization\n----------------------------------\n# Histogram of Losses(not CappedLoss!). too many outliners therefore we capped the loss to 1200. The outliers cause the mean to be higher than it should be, almost makes the median a better measure of central tendency.  By elminating the outliers, the mean becomes a better measure of central tendency.\nhist(Losses,breaks=100, xlab=\"Loss (00s)\",ylab=\"# of Policy\", main=\"Distribution of Capped Loss\")\n\nboxplot(Losses)\n\nmedian(Losses)\nmean(Losses)\n\n# Descriptive- Histogram of Capped.Loss- distribution seems more normal.  Based on the data, we determined that the threshold limit is approximately is 1200.  1% of our observations (156) are outliers.\nhist(Capped.Losses, xlab=\"Capped.Loss (00s)\",ylab=\"# of Policy\", main=\"Distribution of Capped Loss\")\n\n*******For project possibly add gg-plots to show better visualization between each variable and losses********\n\n# Descriptive- Plots for each pair, the color is to make the dots look lighter , easier to see\nplot(Capped.Losses ~Vehicle.Age,col=\"#00000033\")\nplot(Capped.Losses ~Age,col=\"#00000033\")\nplot(Capped.Losses ~Gender,col=\"#00000033\")\nplot(Capped.Losses ~Married,col=\"#00000033\")\nplot(Capped.Losses ~Fuel.Type,col=\"#00000033\")\nplot(Age, Years.of.Driving.Experience,col=\"#00000033\")\nboxplot(Capped.Losses ~Age.Band)\n\n#ggplot- Capped Losses by Age Group (note: the y axis scale seems wrong, I need to fix it)\nqplot(Capped.Losses, data=insurance.data, geom=\"density\", fill=Age.Band, alpha=I(.5), \n      main=\"Distribution of Capped Losses\", xlab=\"Capped.Losses\", \nylab=\"# of Policy\")\n\n\n#ggplot - Capped Losses by Gender\nqplot(Capped.Losses, data=insurance.data, geom=\"density\", fill=Gender, alpha=I(.5), \nmain=\"Distribution of Capped Losses\", xlab=\"Capped.Losses\", \nylab=\"# of Policy\")\n\n#ggplot-  Histogram- Gender + Age Group vs. Mean Capped Losses\n#source: http://stackoverflow.com/questions/17368223/ggplot2-multi-group-histogram-with-in-group-proportions-rather-than-frequency\n\nbar<-ggplot(insurance.data, aes(Gender, Capped.Losses,fill=Age.Band))\nbar+ stat_summary(fun.y=mean,geom=\"histogram\", position=\"dodge\", width=0.2)\n\n\nbar<-ggplot(insurance.data, aes(Married, Capped.Losses,fill=Age.Band))\nbar+ stat_summary(fun.y=mean,geom=\"histogram\", position=\"dodge\", width=0.2)\n\n#Find correlations between variables \n#(I did some research and found that we can only calculate correlations for continuous variables, not discrete ones )\ncor(Age,Avg.Age)\ncor(Years.of.Driving.Experience,Age)\ncor(Vehicle.Age,Avg.Vehicle.Age)\n#interesting finding. include the plot in here.  What other correlation would be useful for presentation?\n\n#Age and experience is highliy correlated. therefore we are dropping one of them as our variables.\ncor(Age,Years.of.Driving.Experience)\n\n\n### DATA DICTIONARY\n#VARIABLE NAME    VARIABLE DESCRIPTION    VALUES STORED    VARIABLE TYPE\n\n### DATA PROFILING\n#TBD\n\n### RESPONSE VARIABLE EXPLORATION\n## Add distribution of dependent variable.  Explain why we used losses.\n##add plots of different pairs of variables, correlation, etc.\n\n####DISTRIBUTION ANALYSIS\n#####PERCENTILES,VARIANCE,FREQ DISTRIBUTION\n\n####OUTLIER TREATMENT\n#####IDENTIFY OUTLIERS/THRESHOLD LIMITS - CAP AT THRESHOLDS\n\n### INDEPENDENT VARIABLE ANALYSIS\n#### INDEPENDENT VARIABLE SELECTION\n#### BIVARIATE ANALYSIS OF RESPONSE AGAINST INDEPENDENT VARIABLES\n#### HETEROSKEDASTICITY\n\n\n\nModel Building\n------------------\n\nVariable Selection\n\n\n### MULTIVARIATE LIN REGRESSION\n#### FITTING THE REGRESSION\n##### MULTICOLLINEARITY CHECK\nage vs avg age\nveh age vs avg veh age\nage vs years of driving exp\n\n##### FIX HETEROSKEDASTICITY\n\n```{r}\nFitLinReg=lm(Capped.Losses~Number.of.Vehicles+Avg.Age+Gender.Dummy+Married.Dummy+Avg.Vehicle.Age+Fuel.Type.Dummy,LinRegData)\nsummary(FitLinReg)\n```\n\nThe following model includes all $x$ varables in the model\n```{r, eval=FALSE}\nmodel_1 <- lm(medv~crim+zn+chas+nox+rm+dis+rad+tax+ptratio+black+lstat, data=Boston_train)\n```\n\nTo include all variables in the model, you can write the statement this simpler way.\n\n\n```{r}\nmodel_1 <- lm(medv~., data=Boston_train)\nsummary(model_1)\n```\n\nEvaluating Model Fitness \n------------\n### In-sample model evaluation (train error)\nMSE of the regression, which is the square of 'Residual standard error' in the above summary. It is the sum of squared residuals(SSE) divided by degrees of freedom (n-p-1). In some textbooks the sum of squred residuals(SSE) is called residual sum of squares(RSS). MSE of the regression should be the unbiased estimator for variance of $\\epsilon$, the error term in the regression model.\n\n```{r}\nmodel_summary <- summary(model_1)\n(model_summary$sigma)^2\n```\n\n$R^2$ of the model\n```{r}\nmodel_summary$r.squared\n```\n\n\nAdjusted-$R^2$ of the model, if you add a variable (or several in a group), SSE will decrease, $R^2$ will increase, but Adjusted-$R^2$ could go either way.\n```{r}\nmodel_summary$adj.r.squared\n```\n\nAIC and BIC of the model, these are information criteria. Smaller values indicate better fit.\n\n```{r}\nAIC(model_1)\nBIC(model_1)\n```\n\nBIC, AIC, and Adjusted $R^2$ have complexity penalty in the definition, thus when comparing across different models they are better indicators on how well the model will perform on future data.\n\n\n### Out-of-sample prediction (test error)\nTo evaluate how the model performs on future data, we use predict() to get the predicted values from the test set.\n```{r, eval=FALSE}\n#pi is a vector that contains predicted values for test set.\npi <- predict(object = model_1, newdata = Boston_test)\n```\nJust as any other function, you can write the above statement the following way as long as the arguments are in the right order.\n\n\n```{r, echo=FALSE}\nsubset <- sample(nrow(Boston),nrow(Boston)*0.90)\nBoston_train = Boston[subset,]\nBoston_test = Boston[-subset,]\nmodel_1 <- lm(medv~., data=Boston_train)\n```\n\n```{r, eval=TRUE}\npi <- predict(model_1, Boston_test)\n```\n\n\nThe most common measure is the Mean Squared Error (MSE): average of the squared differences between the predicted and actual values\n```{r}\nmean((pi - Boston_test$medv)^2)\n```\nA less popular measure is the Mean Absolute Error (MAE). You can probably guess that here instead of taking the average of squared error, MAE is the average of absolute value of error.\n```{r}\nmean(abs(pi - Boston_test$medv))\n```\n\n\nNote that if you ignore the second argument of predict(), it gives you the in-sample prediction on the training set:\n```{r, eval=FALSE}\npredict(model_1)\n```\nWhich is the same as\n```{r, eval=FALSE}\nmodel_1$fitted.values\n```\n\n\nVariable Selection\n------------------------\n### Compare Model Fit Manually\n```{r eval=FALSE}\nmodel_1 <- lm(medv~., data = Boston_train)\nmodel_2 <- lm(medv~crim+zn, data = Boston_train)\nsummary(model_1)\nsummary(model_2)\nAIC(model_1)\nAIC(model_2)\n```\n\n\n### Forward/Backward/Stepwise Regression Using AIC\nTo perform the Forward/Backward/Stepwise Regression in R, we need to define the starting points:\n```{r}\nnullmodel=lm(medv~1, data=Boston_train)\nfullmodel=lm(medv~., data=Boston_train)\n```\nnullmodel is the model with no varaible in it, while fullmodel is the model with every variable in it.\n\n#### Backward Elimination\n```{r}\nmodel.step<-step(fullmodel,direction='backward')\n```\n\n#### Stepwise Selection (Output Omitted)\n```{r, eval=FALSE}\nmodel.step<-step(nullmodel, scope=list(lower=nullmodel, upper=fullmodel), direction='both')\n```\n\nOne caution when comparing fit statistics using AIC, the definition varies by program/procedure.\n```{r}\nextractAIC(model_1)\nAIC(model_1)\n```\n\n\n* For pros and cons of variable/model selection using the common fit statistics: (adjusted) $R^2$, MSE, AIC, BIC, etc. refer to Ch9 in \"Applied Linear Regression Models\" by Kutner et al.\n* For other variable selection methods refer to section 3.4 - 3.8 of [\"Elements of Statistical Learning\" (Free Online)](http://www-stat.stanford.edu/~tibs/ElemStatLearn/).\n\nDiagnostic Plots\n-----------------\nThe diagnostic plots are not as important when regression is used in predictive (supervised) data mining as when it is used in economics. However it is still good to know:\n\n1. What the diagnostic plots should look like when no assumption is violated?\n\n2. If there is something wrong, what assumptions are possibly violated?\n\n3. What implications does it have on the analysis?\n\n4. (How) can I fix it?\n\nRoughly speaking, the table summarizes what you should look for in the following plots\n\nPlot Name  | Good  \n------------- | -------------\nResidual vs. Fitted  | No pattern, scattered around 0 line\nNormal Q-Q | Dots fall on dashed line \nResidual vs. Leverage | No observation with large Cook's distance\n\n```{r}\nplot(model_1)\n```\n\n\n\n",
    "created" : 1417291904077.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2602632119",
    "id" : "BD284E9",
    "lastKnownWriteTime" : 1417300343,
    "path" : "C:/Users/Young Comp/Desktop/statsfinalproject/statsfinalproject/project_final Master - Copy.R",
    "project_path" : "project_final Master - Copy.R",
    "properties" : {
        "notebook_format" : "html_document"
    },
    "source_on_save" : false,
    "type" : "r_source"
}